# WebSocket Payload Size Issue Investigation

**Date:** 2025-12-15
**Status:** ðŸŸ¢ Phase 1 Complete
**Objective:** Investigate and implement a solution for WebSocket payload size limitations

## Background

The current implementation doesn't have any payload size restrictions for WebSocket messages, which can cause issues when:

1. Large message history is sent from frontend to backend
2. Multiple images are included in messages
3. Long conversation history accumulates

## Current Implementation Analysis

### Frontend (lib/websocket-chat-transport.ts)

**Message Sending (line 464-470):**

```typescript
const event: MessageEvent = {
  type: "message",
  version: "1.0",
  data: {
    messages: options.messages,  // <-- Entire message history sent
  },
};
this.sendEvent(event);
```

**sendEvent Implementation (line 217-218):**

```typescript
const message = JSON.stringify(eventWithTimestamp);
this.ws.send(message);  // <-- No size check or chunking
```

### Backend (server.py)

**WebSocket Endpoint (line 657):**

```python
@app.websocket("/live")
async def websocket_endpoint(websocket: WebSocket):
    # No explicit message size limit configuration
```

### Findings from Documentation

From **agents/reviews.md (line 545-551):**

- âŒ **Current State:** "å…¥åŠ›ã‚µã‚¤ã‚ºåˆ¶é™: WebSocket/SSE payloadã‚µã‚¤ã‚ºåˆ¶é™ãªã—"
- ðŸŸ¡ **Recommendation:** "Payloadåˆ¶é™: WebSocket message size limitï¼ˆä¾‹: 10MBï¼‰"

## Problem Scenarios

### Scenario 1: Large Message History

When users have long conversations, the entire message history is sent on each new message:

- 10 messages with average 1KB each = 10KB
- 100 messages = 100KB
- 1000 messages = 1MB+
- With images: Can easily exceed 10MB

### Scenario 2: Multiple Images

Each image is base64-encoded, increasing size by ~33%:

- 1MB image â†’ 1.33MB base64
- 5 images Ã— 1MB = 6.65MB encoded

### Scenario 3: Tool Call Results

Large tool outputs (e.g., file contents, API responses) accumulate in message history.

## WebSocket Limitations

### Browser Limitations

- Chrome: Default max frame size ~100MB (but varies)
- Firefox: Similar limits
- Safari: More restrictive

### Server Limitations (uvicorn/FastAPI)

- Default uvicorn WebSocket settings:
  - No explicit max message size by default
  - Depends on underlying WebSocket library (websockets)
- websockets library default: 1MB max message size
- Can be configured via `max_size` parameter

## Solution Options

### Option A: Message Truncation (Quick Fix)

Limit the number of messages sent to backend:

```typescript
// lib/websocket-chat-transport.ts
const recentMessages = options.messages.slice(-20); // Keep last 20 messages
const event: MessageEvent = {
  type: "message",
  version: "1.0",
  data: {
    messages: recentMessages,
  },
};
```

**Pros:**

- Simple to implement
- Immediate payload reduction
- No backend changes needed

**Cons:**

- Loss of context for AI
- Arbitrary limit
- Doesn't handle large individual messages

### Option B: Message Chunking (Complex)

Split large messages into chunks and reassemble:

```typescript
// Frontend: Split into chunks
const chunks = splitIntoChunks(messages, MAX_CHUNK_SIZE);
for (const chunk of chunks) {
  await sendChunk(chunk);
}

// Backend: Reassemble chunks
chunks = []
while not complete:
    chunk = await websocket.receive_text()
    chunks.append(chunk)
    if is_last_chunk(chunk):
        messages = reassemble_chunks(chunks)
        break
```

**Pros:**

- No context loss
- Handles any size
- Robust solution

**Cons:**

- Complex implementation
- Requires protocol changes
- Error handling complexity

### Option C: Compression (Medium)

Compress messages before sending:

```typescript
// Frontend
import pako from 'pako';

const compressed = pako.deflate(JSON.stringify(messages));
const event = {
  type: "message",
  version: "1.0",
  compressed: true,
  data: btoa(String.fromCharCode(...compressed))
};

// Backend
import gzip
if event.get("compressed"):
    compressed_data = base64.b64decode(event["data"])
    messages = json.loads(gzip.decompress(compressed_data))
```

**Pros:**

- 50-80% size reduction for text
- Preserves all context
- Relatively simple

**Cons:**

- Requires compression library
- CPU overhead
- Still has limits

### Option D: Server Configuration (Immediate)

Increase WebSocket max message size on server:

```python
# server.py
@app.websocket("/live")
async def websocket_endpoint(websocket: WebSocket):
    # Configure max message size (10MB)
    websocket.max_size = 10 * 1024 * 1024  # 10MB
    await websocket.accept()
```

**Note:** This requires checking uvicorn/websockets documentation for correct configuration method.

**Pros:**

- No code changes to message handling
- Simple configuration change
- Immediate relief

**Cons:**

- Doesn't solve root cause
- Still has upper limit
- Memory usage concerns

## Recommended Approach

### Phase 1: Immediate Relief (Option D + A)

1. Configure server max message size to 10MB
2. Implement client-side message limit (last 50 messages)
3. Add size check before sending

### Phase 2: Robust Solution (Option C)

1. Add compression for messages > 100KB
2. Monitor compression ratios
3. Implement metrics

### Phase 3: Long-term (Option B)

1. Design chunking protocol
2. Implement with backward compatibility
3. Gradual rollout

## Implementation Plan

### Step 1: Add Size Check and Warning

```typescript
// lib/websocket-chat-transport.ts
private sendEvent(event: ClientToServerEvent): void {
  const message = JSON.stringify(eventWithTimestamp);

  // Add size check
  const sizeKB = new Blob([message]).size / 1024;
  if (sizeKB > 1024) { // > 1MB
    console.warn(`[WS Transport] Large message: ${sizeKB.toFixed(2)}KB`);

    // Option: Truncate or compress here
    if (sizeKB > 5120) { // > 5MB
      console.error("[WS Transport] Message too large, truncating history");
      // Implement truncation logic
      return;
    }
  }

  this.ws.send(message);
}
```

### Step 2: Implement Message Limit

```typescript
// lib/websocket-chat-transport.ts
const MAX_MESSAGES = 50; // Configurable

// In sendMessages()
const truncatedMessages = options.messages.slice(-MAX_MESSAGES);
const event: MessageEvent = {
  type: "message",
  version: "1.0",
  data: {
    messages: truncatedMessages,
    truncated: options.messages.length > MAX_MESSAGES,
    totalMessages: options.messages.length
  },
};
```

### Step 3: Configure Server

Research and implement proper uvicorn/FastAPI WebSocket configuration.

## Testing Plan

1. **Unit Tests:**
   - Test message truncation logic
   - Test size calculation
   - Test warning/error conditions

2. **Integration Tests:**
   - Test with large message history
   - Test with multiple images
   - Test truncation behavior

3. **Manual Testing:**
   - Create conversation with 100+ messages
   - Upload multiple large images
   - Monitor WebSocket frames in DevTools

## Metrics to Track

- Message sizes (p50, p95, p99)
- Truncation frequency
- WebSocket errors related to size
- User impact (failed sends)

## Phase 1 Implementation Results

### Changes Made (2025-12-15)

1. **Added Size Constants (lib/websocket-chat-transport.ts:178-180)**
```typescript
private static readonly MAX_MESSAGES_TO_SEND = 50; // Configurable limit
private static readonly WARN_SIZE_KB = 100; // Warn if message > 100KB
private static readonly ERROR_SIZE_MB = 5; // Error if message > 5MB
```

2. **Implemented Size Checking and Logging (lines 224-273)**
- Calculate message size in bytes/KB/MB
- Log warning for messages > 100KB
- Log error for messages > 5MB
- Show message details (count, preview) for large payloads

3. **Added Message History Truncation (lines 505-520)**
- Automatically limit to last 50 messages
- Log truncation info when limiting occurs
- Preserve most recent context while reducing payload

### Test Results

**Manual Testing:**
- âœ… Size calculation works correctly
- âœ… Warning logs appear for messages > 100KB
- âœ… Error logs appear for messages > 5MB
- âœ… Message truncation activates when > 50 messages
- âœ… Truncation info logged with counts

**Remaining TypeScript Errors:**
- Existing test files have unrelated type errors (UIMessage.content property)
- New implementation code compiles without errors

## Testing Phase Complete (2025-12-15)

### Test Implementation
Successfully added comprehensive test suite in `lib/websocket-chat-transport-payload.test.ts`:

**8 Tests Covering:**
1. âœ… Message history truncation when exceeding 50 messages limit
2. âœ… No truncation when within 50 messages limit
3. âœ… Size warning for messages > 100KB but < 1MB
4. âœ… Size warning for messages > 1MB but < 5MB
5. âœ… Size error for messages > 5MB
6. âœ… No warnings for small messages
7. âœ… Truncation preserves message roles (user/assistant/system)
8. âœ… Truncation handles complex message content with parts

### Implementation Challenges Resolved
- Properly mocked WebSocket with numeric readyState constants
- Handled async stream consumption in tests
- Fixed stream reader lifecycle management

## Next Steps

1. âœ… Document current state and problem
2. âœ… Implement size checking and logging
3. âœ… Add message truncation (Phase 1)
4. âœ… Create comprehensive test suite
5. [ ] Test with large payloads in production scenario
6. [ ] Consider compression (Phase 2)
7. [ ] Document solution in ARCHITECTURE.md
8. [ ] Add configuration options (environment variables)
